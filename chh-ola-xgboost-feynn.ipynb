{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Fix FutureWarning Messages in scikit-learn\n# import warnings filter\nfrom warnings import simplefilter\n# ignore all future warnings\nsimplefilter(action='ignore', category=FutureWarning)\n\nimport math\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom datetime import datetime, timedelta\nfrom dateutil.parser import parse as dt_parse\nfrom collections import Counter\n\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\nfrom sklearn.metrics import mean_squared_error\n\nimport xgboost as xgb\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 0) Check training file.","metadata":{}},{"cell_type":"code","source":"!head /kaggle/input/chh-ola/train.csv","metadata":{"execution":{"iopub.status.busy":"2023-07-27T14:07:42.322406Z","iopub.execute_input":"2023-07-27T14:07:42.323204Z","iopub.status.idle":"2023-07-27T14:07:43.471688Z","shell.execute_reply.started":"2023-07-27T14:07:42.323122Z","shell.execute_reply":"2023-07-27T14:07:43.470611Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"ID,vendor+AF8-id,pickup+AF8-loc,drop+AF8-loc,driver+AF8-tip,mta+AF8-tax,distance,pickup+AF8-time,drop+AF8-time,num+AF8-passengers,toll+AF8-amount,payment+AF8-method,rate+AF8-code,stored+AF8-flag,extra+AF8-charges,improvement+AF8-charge,total+AF8-amount\n0,1,170,233,1.83,0.5,0.7,04/04/2017 05:59:43 PM,04/04/2017 06:05:04 PM,1,0,1,1,N,1,0.3,9.13\n1,2,151,243,3.56,0.5,4.64,04/03/2017 07:03:34 PM,04/03/2017 07:20:04 PM,1,0,1,1,N,1,0.3,21.36\n2,2,68,90,1.5,0.5,1.29,04/03/2017 03:06:13 PM,04/03/2017 03:12:30 PM,2,0,1,1,N,0,0.3,8.8\n3,2,142,234,1.5,0.5,2.74,04/04/2017 08:10:52 AM,04/04/2017 08:27:00 AM,1,0,1,1,N,0,0.3,14.8\n4,2,238,238,0,0.5,0.45,04/05/2017 02:02:59 PM,04/05/2017 02:05:41 PM,6,0,2,1,N,0,0.3,4.8\n5,1,230,48,1.05,0.5,0.4,04/03/2017 09:10:13 AM,04/03/2017 09:12:09 AM,1,0,1,1,N,0,0.3,5.35\n6,2,236,140,2.46,0.5,1.72,04/03/2017 12:04:52 PM,04/03/2017 12:20:54 PM,3,0,1,1,N,0,0.3,14.76\n7,1,236,13,5.95,0.5,8.8,04/04/2017 03:19:38 PM,04/04/2017 03:48:18 PM,1,0,1,1,N,0,0.3,35.75\n8,1,229,141,0,0.5,1.2,04/05/2017 09:16:22 PM,04/05/2017 09:24:26 PM,2,0,2,1,N,0.5,0.3,8.8\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/chh-ola/train.csv')\ndf","metadata":{"execution":{"iopub.status.busy":"2023-07-27T14:08:34.111318Z","iopub.execute_input":"2023-07-27T14:08:34.111694Z","iopub.status.idle":"2023-07-27T14:08:38.726968Z","shell.execute_reply.started":"2023-07-27T14:08:34.111639Z","shell.execute_reply":"2023-07-27T14:08:38.725970Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"              ID vendor+AF8-id  pickup+AF8-loc  drop+AF8-loc driver+AF8-tip  \\\n0              0             1           170.0         233.0           1.83   \n1              1             2           151.0         243.0           3.56   \n2              2             2            68.0          90.0            1.5   \n3              3             2           142.0         234.0            1.5   \n4              4             2           238.0         238.0              0   \n...          ...           ...             ...           ...            ...   \n1048570  1048570             1            48.0          50.0              1   \n1048571  1048571             1           237.0         166.0              0   \n1048572  1048572             1           164.0          90.0           2.35   \n1048573  1048573             2           264.0         264.0              0   \n1048574  1048574             1            74.0          74.0              0   \n\n        mta+AF8-tax  distance         pickup+AF8-time           drop+AF8-time  \\\n0               0.5      0.70  04/04/2017 05:59:43 PM  04/04/2017 06:05:04 PM   \n1               0.5      4.64  04/03/2017 07:03:34 PM  04/03/2017 07:20:04 PM   \n2               0.5      1.29  04/03/2017 03:06:13 PM  04/03/2017 03:12:30 PM   \n3               0.5      2.74  04/04/2017 08:10:52 AM  04/04/2017 08:27:00 AM   \n4               0.5      0.45  04/05/2017 02:02:59 PM  04/05/2017 02:05:41 PM   \n...             ...       ...                     ...                     ...   \n1048570         0.5      1.40  04/06/2017 11:17:09 PM  04/06/2017 11:25:04 PM   \n1048571         0.5      3.60  04/06/2017 10:58:47 AM  04/06/2017 11:22:04 AM   \n1048572         0.5      1.70  04/06/2017 10:03:42 PM  04/06/2017 10:17:04 PM   \n1048573         0.5      1.80  04/06/2017 06:43:22 PM  04/06/2017 06:56:09 PM   \n1048574         0.5      0.30  04/04/2017 07:45:03 AM  04/04/2017 07:47:49 AM   \n\n         num+AF8-passengers toll+AF8-amount  payment+AF8-method  \\\n0                       1.0               0                 1.0   \n1                       1.0               0                 1.0   \n2                       2.0               0                 1.0   \n3                       1.0               0                 1.0   \n4                       6.0               0                 2.0   \n...                     ...             ...                 ...   \n1048570                 1.0               0                 1.0   \n1048571                 1.0               0                 2.0   \n1048572                 1.0               0                 1.0   \n1048573                 4.0               0                 2.0   \n1048574                 1.0               0                 2.0   \n\n         rate+AF8-code stored+AF8-flag extra+AF8-charges  \\\n0                  1.0               N                 1   \n1                  1.0               N                 1   \n2                  1.0               N                 0   \n3                  1.0               N                 0   \n4                  1.0               N                 0   \n...                ...             ...               ...   \n1048570            1.0               N               0.5   \n1048571            1.0               N                 0   \n1048572            1.0               N               0.5   \n1048573            1.0               N                 1   \n1048574            1.0               N                 0   \n\n        improvement+AF8-charge total+AF8-amount  \n0                          0.3             9.13  \n1                          0.3            21.36  \n2                          0.3              8.8  \n3                          0.3             14.8  \n4                          0.3              4.8  \n...                        ...              ...  \n1048570                    0.3              9.8  \n1048571                    0.3             18.3  \n1048572                    0.3            14.15  \n1048573                    0.3             11.8  \n1048574                    0.3              4.8  \n\n[1048575 rows x 17 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>vendor+AF8-id</th>\n      <th>pickup+AF8-loc</th>\n      <th>drop+AF8-loc</th>\n      <th>driver+AF8-tip</th>\n      <th>mta+AF8-tax</th>\n      <th>distance</th>\n      <th>pickup+AF8-time</th>\n      <th>drop+AF8-time</th>\n      <th>num+AF8-passengers</th>\n      <th>toll+AF8-amount</th>\n      <th>payment+AF8-method</th>\n      <th>rate+AF8-code</th>\n      <th>stored+AF8-flag</th>\n      <th>extra+AF8-charges</th>\n      <th>improvement+AF8-charge</th>\n      <th>total+AF8-amount</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>170.0</td>\n      <td>233.0</td>\n      <td>1.83</td>\n      <td>0.5</td>\n      <td>0.70</td>\n      <td>04/04/2017 05:59:43 PM</td>\n      <td>04/04/2017 06:05:04 PM</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>N</td>\n      <td>1</td>\n      <td>0.3</td>\n      <td>9.13</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>151.0</td>\n      <td>243.0</td>\n      <td>3.56</td>\n      <td>0.5</td>\n      <td>4.64</td>\n      <td>04/03/2017 07:03:34 PM</td>\n      <td>04/03/2017 07:20:04 PM</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>N</td>\n      <td>1</td>\n      <td>0.3</td>\n      <td>21.36</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>68.0</td>\n      <td>90.0</td>\n      <td>1.5</td>\n      <td>0.5</td>\n      <td>1.29</td>\n      <td>04/03/2017 03:06:13 PM</td>\n      <td>04/03/2017 03:12:30 PM</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>N</td>\n      <td>0</td>\n      <td>0.3</td>\n      <td>8.8</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>142.0</td>\n      <td>234.0</td>\n      <td>1.5</td>\n      <td>0.5</td>\n      <td>2.74</td>\n      <td>04/04/2017 08:10:52 AM</td>\n      <td>04/04/2017 08:27:00 AM</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>N</td>\n      <td>0</td>\n      <td>0.3</td>\n      <td>14.8</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>238.0</td>\n      <td>238.0</td>\n      <td>0</td>\n      <td>0.5</td>\n      <td>0.45</td>\n      <td>04/05/2017 02:02:59 PM</td>\n      <td>04/05/2017 02:05:41 PM</td>\n      <td>6.0</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>N</td>\n      <td>0</td>\n      <td>0.3</td>\n      <td>4.8</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>1048570</td>\n      <td>1048570</td>\n      <td>1</td>\n      <td>48.0</td>\n      <td>50.0</td>\n      <td>1</td>\n      <td>0.5</td>\n      <td>1.40</td>\n      <td>04/06/2017 11:17:09 PM</td>\n      <td>04/06/2017 11:25:04 PM</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>N</td>\n      <td>0.5</td>\n      <td>0.3</td>\n      <td>9.8</td>\n    </tr>\n    <tr>\n      <td>1048571</td>\n      <td>1048571</td>\n      <td>1</td>\n      <td>237.0</td>\n      <td>166.0</td>\n      <td>0</td>\n      <td>0.5</td>\n      <td>3.60</td>\n      <td>04/06/2017 10:58:47 AM</td>\n      <td>04/06/2017 11:22:04 AM</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>N</td>\n      <td>0</td>\n      <td>0.3</td>\n      <td>18.3</td>\n    </tr>\n    <tr>\n      <td>1048572</td>\n      <td>1048572</td>\n      <td>1</td>\n      <td>164.0</td>\n      <td>90.0</td>\n      <td>2.35</td>\n      <td>0.5</td>\n      <td>1.70</td>\n      <td>04/06/2017 10:03:42 PM</td>\n      <td>04/06/2017 10:17:04 PM</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>N</td>\n      <td>0.5</td>\n      <td>0.3</td>\n      <td>14.15</td>\n    </tr>\n    <tr>\n      <td>1048573</td>\n      <td>1048573</td>\n      <td>2</td>\n      <td>264.0</td>\n      <td>264.0</td>\n      <td>0</td>\n      <td>0.5</td>\n      <td>1.80</td>\n      <td>04/06/2017 06:43:22 PM</td>\n      <td>04/06/2017 06:56:09 PM</td>\n      <td>4.0</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>N</td>\n      <td>1</td>\n      <td>0.3</td>\n      <td>11.8</td>\n    </tr>\n    <tr>\n      <td>1048574</td>\n      <td>1048574</td>\n      <td>1</td>\n      <td>74.0</td>\n      <td>74.0</td>\n      <td>0</td>\n      <td>0.5</td>\n      <td>0.30</td>\n      <td>04/04/2017 07:45:03 AM</td>\n      <td>04/04/2017 07:47:49 AM</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>N</td>\n      <td>0</td>\n      <td>0.3</td>\n      <td>4.8</td>\n    </tr>\n  </tbody>\n</table>\n<p>1048575 rows × 17 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Step 1) - EDA and Feature Engineering","metadata":{}},{"cell_type":"code","source":"# Summary statistics of the numerical columns\nprint(df.describe())","metadata":{"execution":{"iopub.status.busy":"2023-07-27T14:08:55.992267Z","iopub.execute_input":"2023-07-27T14:08:55.992886Z","iopub.status.idle":"2023-07-27T14:08:56.317690Z","shell.execute_reply.started":"2023-07-27T14:08:55.992816Z","shell.execute_reply":"2023-07-27T14:08:56.316224Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"                 ID  pickup+AF8-loc  drop+AF8-loc      distance  \\\ncount  1.048575e+06    1.048574e+06  1.048574e+06  1.048574e+06   \nmean   5.242870e+05    1.648085e+02  1.626675e+02  2.859832e+00   \nstd    3.026977e+05    6.579282e+01  6.953073e+01  3.709541e+00   \nmin    0.000000e+00    1.000000e+00  1.000000e+00  0.000000e+00   \n25%    2.621435e+05    1.250000e+02  1.130000e+02  9.300000e-01   \n50%    5.242870e+05    1.620000e+02  1.620000e+02  1.600000e+00   \n75%    7.864305e+05    2.330000e+02  2.330000e+02  2.900000e+00   \nmax    1.048574e+06    2.650000e+02  2.650000e+02  1.138000e+02   \n\n       num+AF8-passengers  payment+AF8-method  rate+AF8-code  \ncount        1.048574e+06        1.048574e+06   1.048574e+06  \nmean         1.590696e+00        1.317943e+00   1.043368e+00  \nstd          1.253700e+00        4.853266e-01   5.621114e-01  \nmin          0.000000e+00        1.000000e+00   1.000000e+00  \n25%          1.000000e+00        1.000000e+00   1.000000e+00  \n50%          1.000000e+00        1.000000e+00   1.000000e+00  \n75%          2.000000e+00        2.000000e+00   1.000000e+00  \nmax          9.000000e+00        4.000000e+00   9.900000e+01  \n","output_type":"stream"}]},{"cell_type":"code","source":"# Check the data types and missing values in each column\nprint(df.info())","metadata":{"execution":{"iopub.status.busy":"2023-07-27T14:09:14.392235Z","iopub.execute_input":"2023-07-27T14:09:14.392681Z","iopub.status.idle":"2023-07-27T14:09:15.508244Z","shell.execute_reply.started":"2023-07-27T14:09:14.392593Z","shell.execute_reply":"2023-07-27T14:09:15.507291Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1048575 entries, 0 to 1048574\nData columns (total 17 columns):\nID                        1048575 non-null int64\nvendor+AF8-id             1048575 non-null object\npickup+AF8-loc            1048574 non-null float64\ndrop+AF8-loc              1048574 non-null float64\ndriver+AF8-tip            1048573 non-null object\nmta+AF8-tax               1048574 non-null object\ndistance                  1048574 non-null float64\npickup+AF8-time           1048574 non-null object\ndrop+AF8-time             1048574 non-null object\nnum+AF8-passengers        1048574 non-null float64\ntoll+AF8-amount           1048573 non-null object\npayment+AF8-method        1048574 non-null float64\nrate+AF8-code             1048574 non-null float64\nstored+AF8-flag           1048574 non-null object\nextra+AF8-charges         1048574 non-null object\nimprovement+AF8-charge    1048573 non-null object\ntotal+AF8-amount          1048573 non-null object\ndtypes: float64(6), int64(1), object(10)\nmemory usage: 136.0+ MB\nNone\n","output_type":"stream"}]},{"cell_type":"code","source":"# Pairplot to visualize relationships between numerical columns (be cautious if the dataset is large)\nsns.pairplot(df) # takes about 10 mins to run\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-27T14:09:50.501247Z","iopub.execute_input":"2023-07-27T14:09:50.501640Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.6/site-packages/numpy/lib/histograms.py:824: RuntimeWarning: invalid value encountered in greater_equal\n  keep = (tmp_a >= first_edge)\n/opt/conda/lib/python3.6/site-packages/numpy/lib/histograms.py:825: RuntimeWarning: invalid value encountered in less_equal\n  keep &= (tmp_a <= last_edge)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-1735eca76e8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Pairplot to visualize relationships between numerical columns (be cautious if the dataset is large)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"],"ename":"NameError","evalue":"name 'plt' is not defined","output_type":"error"}]},{"cell_type":"code","source":"# Correlation heatmap to identify correlations between numerical columns\ncorrelation_matrix = df.corr()\nplt.figure(figsize=(10, 8))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\nplt.title('Correlation Heatmap')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Distribution plot for a numerical column (e.g., distance)\nsns.histplot(df['distance'], kde=True)\nplt.title('Distribution of Distance')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Bar plot for a categorical column (e.g., payment_Method)\nsns.countplot(x='payment_Method', data=df)\nplt.title('Payment Method Distribution')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Box plot to visualize the distribution and outliers of a numerical column (e.g., total_amount)\nsns.boxplot(x='total_amount', data=df)\nplt.title('Total Amount Distribution')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scatter plot to observe the relationship between two numerical columns (e.g., distance vs. total_amount)\nsns.scatterplot(x='distance', y='total_amount', data=df)\nplt.title('Distance vs. Total Amount')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Bar plot for a categorical column with hue (e.g., payment_Method with vendor_id as hue)\nsns.countplot(x='payment_Method', hue='vendor_id', data=df)\nplt.title('Payment Method Distribution with Vendor ID')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.violinplot(x='vendor_id', y='driver_tip', data=df)\nplt.title('Tip Distribution by Vendor ID')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.boxplot(x='payment_Method', y='total_amount', data=df)\nplt.title('Fare Amount by Payment Method')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.boxplot(x='vendor_id', y='total_amount', hue='payment_Method', data=df)\nplt.title('Fare Amount by Vendor ID with Payment Method')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extract the Geographic Segment - Analyze popular pickup and drop locations\npickup_counts = df['pickup_loc'].value_counts()\ndrop_counts = df['drop_loc'].value_counts()\n\n# Visualize popular pickup locations\nplt.figure(figsize=(10, 6))\nsns.barplot(x=pickup_counts.index, y=pickup_counts.values)\nplt.title('Popular Pickup Locations')\nplt.xlabel('Location ID')\nplt.ylabel('Count')\nplt.xticks(rotation=90)\nplt.show()\n\n# Visualize popular drop locations\nplt.figure(figsize=(10, 6))\nsns.barplot(x=drop_counts.index, y=drop_counts.values)\nplt.title('Popular Drop Locations')\nplt.xlabel('Location ID')\nplt.ylabel('Count')\nplt.xticks(rotation=90)\nplt.show()\n\n# Extract the Behavioral Segment - Analyze fare amounts, extra charges, and tipping behavior\nplt.figure(figsize=(10, 6))\nsns.boxplot(x='rate_code', y='total_amount', data=df)\nplt.title('Fare Amount by Rate Code')\nplt.xlabel('Rate Code')\nplt.ylabel('Total Amount')\nplt.show()\n\nplt.figure(figsize=(10, 6))\nsns.boxplot(x='payment_Method', y='total_amount', data=df)\nplt.title('Fare Amount by Payment Method')\nplt.xlabel('Payment Method')\nplt.ylabel('Total Amount')\nplt.show()\n\nplt.figure(figsize=(10, 6))\nsns.boxplot(x='payment_Method', y='driver_tip', data=df)\nplt.title('Tip Distribution by Payment Method')\nplt.xlabel('Payment Method')\nplt.ylabel('Driver Tip')\nplt.show()\n\n# Analyze spending patterns based on payment methods\npayment_spending = df.groupby('payment_Method')['total_amount'].mean().reset_index()\n\nplt.figure(figsize=(8, 5))\nsns.barplot(x='payment_Method', y='total_amount', data=payment_spending)\nplt.title('Average Spending by Payment Method')\nplt.xlabel('Payment Method')\nplt.ylabel('Average Total Amount')\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 2) Cleaning the data using bash is faster than in Python.","metadata":{}},{"cell_type":"code","source":"!sed 's/\\+AF8-//g' /kaggle/input/chh-ola/train.csv > train.csv\n!sed 's/_//g' /kaggle/input/chh-ola/test.csv > test.csv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 3) Write some utility functions","metadata":{}},{"cell_type":"code","source":"class Ut:\n  @staticmethod\n  def to_timestamp(dt):\n    return dt_parse(dt, dayfirst=False).timestamp()\n\n  @staticmethod\n  def flag_to_num(vl):\n    if vl == 'N':\n      return 0\n    else:\n      return 1\n  \n  @staticmethod\n  def to_float(vl):\n    try:\n      if type(vl) == type('str'):\n        idx = vl.find('-')\n        if idx != -1:\n          txt = vl.split('-')\n          return float(txt[1])\n      return float(vl)\n    except:\n      print(vl)\n      return float(0)\n\n  @staticmethod\n  def rmse(predictions, targets):\n    \"\"\"Data convertion and RMSE calculation\"\"\"\n    return np.sqrt(mean_squared_error(np.exp(predictions), np.exp(targets)))","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 4) Data preprocessing","metadata":{}},{"cell_type":"code","source":"# Load training data file\ntrain_set = pd.read_csv('train.csv', low_memory=False, dtype=str)\ntrain_set.dropna(inplace=True)\ntrain_set.reset_index(drop=True, inplace=True)\n\n# Load testing data file\ntest_set = pd.read_csv('test.csv', low_memory=False, dtype=str)\ntest_set['totalamount'] = 0\n\n# Create a column to distinguish one from the other\ntrain_set['PROPOSITO'] = 1\ntest_set['PROPOSITO'] = 0\n\n# Concatenate all data into one dataframe\nall_set = pd.concat([train_set, test_set], ignore_index=True)\n\n# Delete train_set and test_set to free memory\ndel(train_set)\ndel(test_set)\n\n# MTA Tax should be the same in all rides\nall_set['mtatax'] = 0.5\n\n# Data conversion\n# Y or N to 1 or 0\nall_set['storedflag'] = all_set['storedflag'].apply(Ut.flag_to_num)\n# Conversion to datetime format\nall_set['pickuptime'] = all_set['pickuptime'].apply(Ut.to_timestamp)\nall_set['droptime'] = all_set['droptime'].apply(Ut.to_timestamp)\n# Conversion to float\nall_set['drivertip'] = all_set['drivertip'].apply(Ut.to_float)\nall_set['mtatax'] = all_set['mtatax'].apply(Ut.to_float)\nall_set['tollamount'] = all_set['tollamount'].apply(Ut.to_float)\nall_set['extracharges'] = all_set['extracharges'].apply(Ut.to_float)\nall_set['improvementcharge'] = all_set['improvementcharge'].apply(Ut.to_float)\nall_set['totalamount'] = all_set['totalamount'].apply(Ut.to_float)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 5) Feature creation: **total time** and **taxes**.","metadata":{}},{"cell_type":"code","source":"# Total time\nall_set['totaltime'] = all_set['droptime'] - all_set['pickuptime']\n# All Taxes\nall_set['taxes'] = all_set['drivertip'] + all_set['mtatax'] + all_set['tollamount'] + all_set['extracharges'] + all_set['improvementcharge']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 6) Feature analysis and type convertion.","metadata":{}},{"cell_type":"code","source":"features_cat = ['vendorid', 'paymentmethod', 'ratecode', 'storedflag']\nfeatures_num = ['drivertip', 'pickuploc', 'droploc', 'mtatax', 'distance', 'pickuptime', 'droptime', 'numpassengers', \n                'tollamount', 'extracharges', 'improvementcharge', 'totalamount', 'totaltime', 'taxes']\ntarget = 'totalamount'\n\n# Numerical features will be converted to float.\nfor col in features_num:\n    all_set[col] = all_set[col].astype(float)\n\n# Categorical features will be converted to float then to string.    \nfor col in features_cat:\n    all_set[col] = all_set[col].astype(float)\n    all_set[col] = all_set[col].astype(str)\n\nall_set['PROPOSITO'] = all_set['PROPOSITO'].astype(int)\nall_set['ID'] = all_set['ID'].astype(int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 7) Split data into *train_df* and *test_df*","metadata":{}},{"cell_type":"code","source":"# Convert categorical variable into dummy/indicator variables\nall_dum = pd.get_dummies(all_set)\n\ntrain_df = all_dum[all_dum['PROPOSITO'] == 1].copy()\ntest_df = all_dum[all_dum['PROPOSITO'] == 0].copy()\n\ndel(all_dum)\n\ntrain_df.drop(columns=['PROPOSITO'], inplace=True)\ntest_df.drop(columns=['PROPOSITO'], inplace=True)\n\n# Remove rows where pickup loc is equal to drop loc\ntrain_df = train_df[train_df['pickuploc'] != train_df['droploc']]\n# Drop rows where total amount is 0, since there are no free rides\ntrain_df = train_df[train_df['totalamount'] > 0]\ntest_df.drop(columns=[target], inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 8) Normalize data\nNormalized data provide better results on the model. \n* The data will be normalized using **sklearn.preprocessing.Normalizer()**. \n* The targets will be normalized using **numpy.log**. ","metadata":{}},{"cell_type":"code","source":"# Alongside hyperparameter searching, I also did a feature searching to check \n# which combination would provide better results\nfeatures_to_keep = [\n  'taxes',\n  'pickuploc',\n  'ratecode_2.0',\n  'ratecode_1.0',\n  'ratecode_5.0',\n  'storedflag_0.0',\n  'ratecode_4.0',\n  'totaltime',\n  'ratecode_3.0',\n  'droploc',\n  'numpassengers',\n  'distance',\n  'storedflag_1.0',\n  'vendorid_2.0',\n  'paymentmethod_1.0',\n  'vendorid_1.0',\n  'paymentmethod_2.0'\n  ]\n\nX = train_df[features_to_keep].copy()\ny = train_df[target].copy()\n\nnormalizer = Normalizer()\nnorm_X = normalizer.fit_transform(X)\ny = np.log(y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 9) Hyperparameter searching","metadata":{}},{"cell_type":"markdown","source":"### a) GridSearchCV","metadata":{}},{"cell_type":"code","source":"if False:\n  params = {\n      'colsample_bytree':[0.9], \n      'gamma':[0.3],\n      'max_depth': [9],  \n      'min_child_weight':[2], \n      'subsample':[0.9],\n      'n_estimators': [50],\n      'objective': ['reg:squarederror'],\n      'n_jobs': [8],\n      }\n\n  # Initialize XGB and GridSearch\n  eval_model = xgb.XGBRegressor(nthread=-1) \n\n  grid = GridSearchCV(eval_model, params, cv=2)\n  grid.fit(train_X, train_y)\n\n  pred_y = grid.predict(test_X)\n  print('RMSE Test = ', Ut.rmse(pred_y, test_y))\n\n  print(grid)\n  print(grid.best_params_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### b) RandomizedSearchCV","metadata":{}},{"cell_type":"code","source":"if False:\n  params = {\n      'min_child_weight': st.randint(2, 9), \n      'gamma': st.uniform(0.1, 0.9),  \n      'subsample': st.uniform(0.1, 0.9),\n      'colsample_bytree': st.uniform(0.1, 0.9), \n      'max_depth': st.randint(3, 9),\n      'n_estimators': [50],\n      'objective': ['reg:squarederror'],\n      # 'n_jobs': [8],\n      }\n\n  eval_model = xgb.XGBRegressor(nthread=-1) \n\n  grid = RandomizedSearchCV(eval_model, params, cv=2, n_jobs=1, n_iter=10)\n  grid.fit(train_X, train_y)\n\n  pred_y = grid.predict(test_X)\n  print('RMSE Test = ', Ut.rmse(pred_y, test_y))\n\n  print(grid)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### c) Feature searching","metadata":{}},{"cell_type":"code","source":"# Besides hyperparameter searching, it is also important to see how the results change \n# when we remove features that have a poor correlation to the \"total amount\".\nif False:\n    train_correlation = train_df.corr()\n    train_correlation = train_correlation['totalamount'].apply(abs)\n    train_correlation = train_correlation.sort_values(na_position='first')\n    train_correlation = pd.DataFrame(train_correlation).reset_index()\n    train_correlation.dropna(inplace=True)\n    \n    best_rmse = math.inf\n    best_idx = 0\n\n    features_to_analyse = train_correlation['index'].unique()\n    for idx in range(len(features_to_analyse) - 1):\n        features = features_to_analyse[idx:]\n        dX = train_df[features].copy()\n        dy = train_df[target].copy()\n\n        normalizer = Normalizer()\n        norm_dX = normalizer.fit_transform(dX)\n        dy = np.log(dy)\n\n        train_dX, test_dX, train_dy, test_dy = train_test_split(norm_dX, dy, test_size=0.2, random_state=42)\n\n        params = {\n            'objective': 'reg:squarederror',\n            'n_estimators': 100,\n            'subsample': 0.9, \n            'min_child_weight': 1, \n            'max_depth': 9,\n            'gamma': 0.3, \n            'colsample_bytree': 0.9,\n            'n_jobs': 8,\n            'verbose_eval':'False',\n        }\n        model = xgb.XGBRegressor(**params)\n        model.fit(train_dX,train_dy)\n\n        pred_dy = model.predict(test_dX)\n        print('Features cut = ', idx, ' Resulting RMSE = ', Ut.rmse(pred_dy, test_dy))\n        \n        if best_rmse > rmse_res:\n            best_rmse = rmse_res\n            best_idx = idx\n\n    print('Features cut = ', best_idx, ' Resulting RMSE = ', best_rmse)\n    features_to_keep = features_to_analyse[best_idx:]","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 10) Model training","metadata":{}},{"cell_type":"code","source":"train_X, test_X, train_y, test_y = train_test_split(norm_X, y, test_size=0.2, random_state=42)\n\n# These hyperparameters are the result of the searchings of Step 9\nparams = {\n    'objective': 'reg:squarederror',\n    'n_estimators': 1000,\n    'subsample': 0.9, \n    'min_child_weight': 1, \n    'max_depth': 9,\n    'gamma': 0.3, \n    'colsample_bytree': 0.9,\n    'n_jobs': 8,\n    'verbose_eval':'False',\n}\nmodel = xgb.XGBRegressor(**params)\nmodel.fit(train_X,train_y)\n\npred_y = model.predict(test_X)\nprint('RMSE Test = ', Ut.rmse(pred_y, test_y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 11) Prediction","metadata":{}},{"cell_type":"code","source":"real_X = normalizer.transform(test_df[features_to_keep].copy())\n\nmodel = xgb.XGBRegressor(**params)\nmodel.fit(norm_X, y)\n\npredictions = np.exp(model.predict(real_X))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Have a glimpse of the predictions\npd.DataFrame(predictions).head(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 12) Saving the results","metadata":{}},{"cell_type":"code","source":"result = []\nfor idx in range(test_df.shape[0]):\n  result.append([idx, predictions[idx]])\nresult = pd.DataFrame(result, columns=['ID', 'total_amount'])\nresult.to_csv('result.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Delete temp files so they're not taken as results by mistake\n!rm train.csv\n!rm test.csv","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}